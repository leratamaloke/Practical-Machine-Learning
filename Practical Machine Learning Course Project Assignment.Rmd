---
title: "Practical Machine Learning Course Project Assignment"
author: "Lerata Maloke" 
date: "March 16, 2021"
output: "html_document"
---

## Predictions using the Weight Lifting Exercise Dataset

## 1 - Summary
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement ??? a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. 

One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

This project has the purpose to predict the manner in which users perform the exercises. There are 5 possible results, reported in the `classe` variable:

* A: exactly according to the specification
* B: throwing the elbows to the front
* C: lifting the dumbbell only halfway
* D: lowering the dumbbell only halfway
* E: throwing the hips to the front

The objective of this project is to predict the `classe` based on data from accelerometers on the belt, forearm, arm, and dumbbell of 6 participants.

## 2 - Libraries

```{r, echo=TRUE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE, fig.width=10, fig.height=5)
options(width=120)
library(lattice); library(ggplot2); library(plyr)
library(caret); library(randomForest); library(rpart);library(rpart.plot); library(tree)
library(rattle)
set.seed(6266) # set contact random seed
```

## 3 - Dataset Loading

## 4 - Wrangling Dataset
Organizing a new dataset with only the data that is necessary for EDA and ML Training data.

```{r, echo=TRUE}
## Reading dataset and replacing NA Strings with NA
training <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!",""))
testing <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""))
dim(training); dim(testing)
```

```{r,echo=TRUE}
##  Some variables (7 first columns with 'X', 'user_name', 'raw_timestamp_part_1', 'raw_timestamp_part_2', 
##  'cvtd_timestamp', 'new_window', 'num_window') can be deleted because will not useful to this Project.
training <- training[,-c(1:7)]
testing <- testing[,-c(1:7)]
dim(training); dim(testing)
```

```{r,echo=TRUE}
# Delete columns with all missing values
training <- training[ , colSums(is.na(training)) == 0]
testing <- testing[ , colSums(is.na(testing)) == 0]
dim(training); dim(testing)
```

With our cleanup, as you can see, now we have a reduced number of variables, that will be used for analysis.

## 5 - Plotting Dataset for EDA
This project has purpose to predict the manner in which users perform the exercises based on variable `classe` classified as A,B,C,D and E. 

Lets use the variable `classe` in the plot, to see the frequency of each levels in training dataset.

The A classe seems to be the most frequent and D classe the least.

## 6 - Partition Training Dataset 

To enable cross-validation lets make two subsets using 70% for Training and 30% for Testing.
This method will allow us to apply ML Prediction Models and evaluate bias and variance.

```{r,echo=TRUE}
partition <- createDataPartition(y=training$classe, p=0.7, list=FALSE)
trainingSet <- training[partition, ] 
testingSet <- training[-partition, ]
rm(partition)
```

## 7 - Predictions Models

Lets implement the Regression Tree model and Random Forest.

### 7.1 - Regression Tree

Decision tree model is good for classification problems.

### 7.2 - RPart from the Caret package.

```{r, echo=TRUE}
rpartFit <- train(classe ~ .,method="rpart",data=trainingSet) #library Caret
print(rpartFit$finalModel)
fancyRpartPlot(rpartFit$finalModel) #library Rattle
```

Rpart has a little much accurate result than Tree.
Rpart has some methods, and one of them is `class` with good precision.
Lets try it. te. See below.

```{r,echo=TRUE}
classFit <- rpart(classe ~ ., data=trainingSet, method="class") #library caret
fancyRpartPlot(classFit, sub = "") #library Rattle
```

Now,lets see how well it is predicting our test data:

The accuracy shows a good results using Rpart, but a great Regression Method, used for resolution of problems in Kaggle, is Random Forests. Lets apply it now into our Project. 

### 7.3 - Random Forest

As seen by the result of the confusionmatrix, the accuracy for random forests was 0.9958 (very good sensitivity and specificity values) whereas the decision tree was 0.69.
The accuracy is above 99% for the random forest model in our cross-validation data with few misclassifications as compared to the decision tree model.

## 8 - Submission Data for Grading

### 8.1 - Trained Model on the Twenty Testing Data

Random Forests was the choose for this project. Lets apply it to our Testing dataset using the predictor on the test data.

The answer above is the model machine learning algorithm applied to the 20 test cases available in the test data. It scores 100% of the submission (the 20 values to be predict), that will be submitted to answer the questions of Course Project Prediction Quiz. 
